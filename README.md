# mini-RAG-System

# 项目总结：轻量化 RAG 系统的实现与优化

### 背景
传统生成式 AI 系统需要大规模模型和硬件资源以提供高质量回答。然而，我的硬件资源有限（仅 200MB 内存），需要一种轻量级方案来实现高效的问答系统。

### 目标
1. **通过 LoRA（Low-Rank Adaptation）** 实现模型的参数高效微调。
2. **构建轻量化 RAG（Retrieval-Augmented Generation）系统**，结合上下文检索与文本生成。
3. 探索 **Prompt Engineering** 的优化方法，提升生成质量。

---

## 方法与实现

### 1. RAG 系统的特点与逻辑

- **工作流程**：
  1. 使用 TF-IDF 对文档集进行向量化处理。
  2. 计算查询与文档的余弦相似度，检索最相关的上下文。
  3. 将检索到的上下文拼接到 Prompt 中，输入生成模型生成答案。

- **问题解决**：
  - 通过 TF-IDF 和轻量级模型 DistilGPT2 的结合，解决了硬件受限环境下无法运行大型生成模型的问题。

---

### 2. LoRA 在模型微调中的应用

- **原理**：通过低秩分解，仅对部分 Transformer 模块的权重进行更新，实现参数高效微调。
- **关键参数**：
  - **r**：8，表示低秩矩阵的维度。
  - **lora_alpha**：32，调整更新幅度的放大系数。
  - **lora_dropout**：0.1，引入少量随机性以提升鲁棒性。
  - **target_modules**：设置目标模块为 `c_attn` 和 `c_proj`，以降低计算负担。

- **尝试的参数组合与效果**：
    **r=4, lora_alpha=16**：训练速度加快，但生成质量下降明显。

---

### 3. Prompt Engineering 的探索

- **设计逻辑**：
  - **标准模式**：简单的 Prompt，直接给出上下文和查询（`Context → Query → Answer`）。
  - **CoT（Chain-of-Thought）模式**：引导模型逐步推理（`逐步提取上下文信息 → 回答问题`）。

- **改进点**：
  - 调整 Prompt 内容与结构，解决简单 Prompt 在复杂问题上的回答质量低的问题。
  - 引入 CoT 模式，大幅提升复杂问题的推理能力。

- **问题解决**：
  - Prompt Engineering 成功弥补了 DistilGPT2 在深度推理任务中的不足。
---

## 局限性与未来改进

1. **局限性**：
   - TF-IDF 检索方法的效果依赖文档质量，难以扩展到大规模知识库。
   - DistilGPT2 的生成深度有限，复杂场景下仍有优化空间。

2. **未来改进方向**：
   - 尝试引入 Dense Retrieval（如基于向量搜索的检索）提升检索效果。

---
